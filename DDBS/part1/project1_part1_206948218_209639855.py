# -*- coding: utf-8 -*-
"""project1_part1_206948218_209639855.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-XdPwHc9DYtfUYbfVs9RSnbi7q2HIcRe

#Part 1 - Extract and Transform
---
"""

# importing
import os
import re
import findspark
findspark.init()
from pyspark.sql import SparkSession
from pyspark.sql.functions import substring
from pyspark.sql.functions import from_json
from pyspark.sql.functions import col,lit
from pyspark.sql.functions import when
from pyspark.sql.functions import size
from pyspark.sql.functions import array_remove ,array_contains , array_intersect
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from os import path
from PIL import Image
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from IPython.display import display_html 
from pyspark.sql.types import StructField, StructType, StringType, DoubleType, IntegerType , DataType ,LongType , ArrayType , json , DateType

def init_spark(app_name: str):
  spark = SparkSession.builder.appName(app_name).getOrCreate()
  sc = spark.sparkContext
  return spark, sc

spark, sc = init_spark('demo')
sc

#files
file_credits='credits.csv'
file_movies='movies.csv'
file_queries='queries.csv'
file_tickets='tickets.csv'
file_users='users.csv'

#loading the users file
users = spark.read.option("Header", "true")\
        .option("multiline", "true")\
        .option("escape", "\"")\
        .csv(file_users)

#loading the movies file
movies = spark.read.option("Header", "true")\
        .option("multiline", "true")\
        .option("escape", "\"")\
        .csv(file_movies)
#transformations for movies
## dropping irrelevant columns
cols_to_drop_movies = ['overview', 'revenue', 'tagline']
movies = movies.drop(*cols_to_drop_movies)

##extracting from relase_date column the year
movies = movies.withColumn('release_date', substring('release_date', 7,9))

##extracting necessary information from the structured columns
columns = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'cities']
schema = ['array<struct<id:int , name:string>>',
              'array<struct<name:string, id:int>>', 
              'array<struct<iso_3166_1:string , name:string>>',
              'array<struct<iso_639_1:string , name:string>>',
              'array<string>']

for column, field in zip(columns, schema):
    movies = movies.withColumn(column, from_json(col(column), lit(field)))

movies = movies.withColumn('genres', movies.genres['name']).withColumn('production_companies', movies.production_companies['name'])\
    .withColumn('production_countries', movies.production_countries['name']).withColumn('spoken_languages', movies.spoken_languages['name'])\
    .withColumn('spoken_languages', array_remove('spoken_languages', "?????")).withColumn('spoken_languages', array_remove('spoken_languages', "??????"))\
    .withColumn('spoken_languages', array_remove('spoken_languages',""))

#loading the credits file using pandas and regex
credits_pd = pd.read_csv('credits.csv')
credits_pd['cast']= [re.findall("(?<='name':\s)'[\w]*[(\._\-\s)*\w*]*'", i, flags=0) for i in credits_pd['cast']]
credits_pd['crew']= [re.findall("(?<='Director', 'name':\s)'[\w]*[(\._\-\s)*\w*]*'", i, flags=0) for i in credits_pd['crew']]
credits =  spark.createDataFrame(credits_pd)

#loading the queries file
queries = spark.read.option("Header", "true")\
        .option("multiline", "true")\
        .option("escape", "\"")\
        .csv(file_queries)

##extracting from relase_date column the year
queries = queries.withColumn('from_realese_date', substring('from_realese_date', 3,4))

#loading the tickets file
tickets = spark.read.option("Header", "true")\
        .option("multiline", "true")\
        .option("escape", "\"")\
        .csv(file_tickets)

cols_to_drop_tickets = ['cinema_id']
tickets = tickets.drop(*cols_to_drop_tickets)